{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e46f3cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2396d654",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6eb0b3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e445c2",
   "metadata": {},
   "source": [
    "### Check head and info of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91b2df31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b50fa276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001fc161",
   "metadata": {},
   "source": [
    "### Checking for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fddf86c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd4e9dd",
   "metadata": {},
   "source": [
    "### Is there a missing data [how many and the precentage if there]?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71d5161c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "keyword       61\n",
       "location    2533\n",
       "text           0\n",
       "target         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b620822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of missing data is:  34.073295678444765 %\n"
     ]
    }
   ],
   "source": [
    "missing_data_percentage_percolumn= data.isna().sum() * 100 / len(data)\n",
    "print('Percentage of missing data is: ',missing_data_percentage_percolumn[1] + missing_data_percentage_percolumn[2],'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3658ccb4",
   "metadata": {},
   "source": [
    "### How many data in each class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f38faadb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd7688a",
   "metadata": {},
   "source": [
    "##### There are 3271 disaster tweets and 4342 that are not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58a9134",
   "metadata": {},
   "source": [
    "### Get the top 15 locations of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "02a0e0cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "USA                104\n",
       "New York            71\n",
       "United States       50\n",
       "London              45\n",
       "Canada              29\n",
       "Nigeria             28\n",
       "UK                  27\n",
       "Los Angeles, CA     26\n",
       "India               24\n",
       "Mumbai              22\n",
       "Washington, DC      21\n",
       "Kenya               20\n",
       "Worldwide           19\n",
       "Australia           18\n",
       "Chicago, IL         18\n",
       "Name: location, dtype: int64"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['location'].value_counts().head(15)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2035c0",
   "metadata": {},
   "source": [
    "### Get the top 15 keywords of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "a61f1722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "collision           36\n",
       "whirlwind           33\n",
       "armageddon          32\n",
       "fatalities          32\n",
       "flames              31\n",
       "emergency%20plan    31\n",
       "derailed            31\n",
       "outbreak            31\n",
       "sandstorm           31\n",
       "danger              30\n",
       "inundated           30\n",
       "harm                30\n",
       "damage              30\n",
       "desolation          30\n",
       "upheaval            30\n",
       "Name: keyword, dtype: int64"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['keyword'].value_counts().head(15) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7f8743",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a12bca9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2ebeb76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>48</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>@bbcmtd Wholesale Markets ablaze http://t.co/l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>49</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Est. September 2012 - Bristol</td>\n",
       "      <td>We always try to bring the heavy. #metal #RT h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>50</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>AFRICA</td>\n",
       "      <td>#AFRICANBAZE: Breaking news:Nigeria flag set a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>52</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>Crying out for more! Set me ablaze</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>53</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>London, UK</td>\n",
       "      <td>On plus side LOOK AT THE SKY LAST NIGHT IT WAS...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id keyword                       location  \\\n",
       "31  48  ablaze                     Birmingham   \n",
       "32  49  ablaze  Est. September 2012 - Bristol   \n",
       "33  50  ablaze                         AFRICA   \n",
       "34  52  ablaze               Philadelphia, PA   \n",
       "35  53  ablaze                     London, UK   \n",
       "\n",
       "                                                 text  target  \n",
       "31  @bbcmtd Wholesale Markets ablaze http://t.co/l...       1  \n",
       "32  We always try to bring the heavy. #metal #RT h...       0  \n",
       "33  #AFRICANBAZE: Breaking news:Nigeria flag set a...       1  \n",
       "34                 Crying out for more! Set me ablaze       0  \n",
       "35  On plus side LOOK AT THE SKY LAST NIGHT IT WAS...       0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "365e4a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5080 entries, 31 to 7581\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        5080 non-null   int64 \n",
      " 1   keyword   5080 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      5080 non-null   object\n",
      " 4   target    5080 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 238.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1f1b0d",
   "metadata": {},
   "source": [
    "## Preprocessing the tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6af5a6",
   "metadata": {},
   "source": [
    "#### Downloading the english stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "554c2a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lapcell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e51aa31",
   "metadata": {},
   "source": [
    "### What are the most common stop words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c9037fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stopwords(tweets):\n",
    "    stopwords=[]\n",
    "    for tweet in tweets:\n",
    "        for word in tweet.split():\n",
    "            if word.lower() in stop_words:\n",
    "                stopwords.append(word.lower())\n",
    "    return stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c8498bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_stopwords=get_stopwords(data['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c5bcb5",
   "metadata": {},
   "source": [
    "#### Applying the lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e26841b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\lapcell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df62f385",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "le=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "0a410acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(tweets):\n",
    "    clean_tweets=[]\n",
    "    for tweet in tweets:\n",
    "         #Removing mentions and tags\n",
    "        tweet=re.sub(r'(#|@)[a-zA-Z0-9_]+','',tweet)\n",
    "         #Removing links\n",
    "        tweet=re.sub(r'https?:\\/\\/\\S+','',tweet)\n",
    "         #Removing punctuations\n",
    "        tweet=re.sub('\\W',' ',tweet)\n",
    "         #Removing digits\n",
    "        tweet=re.sub(r'\\s[0-9]+\\s','',tweet)\n",
    "         #Removing stand alone characters\n",
    "        tweet=re.sub('\\s[a-zA-Z]\\s','',tweet)\n",
    "         #Removing spaces at the beginning\n",
    "        tweet=re.sub('^\\s+','',tweet)\n",
    "         #Removing spaces at the end\n",
    "        tweet=re.sub('\\s+$','',tweet)\n",
    "        \n",
    "        clean_tweet=[le.lemmatize(word.lower()) for word in tweet.split()  if word.lower() not in stop_words]\n",
    "        clean_tweets.append(clean_tweet)\n",
    "    return clean_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063b27c2",
   "metadata": {},
   "source": [
    "## Building the frequency table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e6d366f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_freq_dict(tweets,target):\n",
    "    freq={}\n",
    "    #key=word\n",
    "    for i in range(len(tweets)):\n",
    "        for word in tweets[i]:\n",
    "            key=word\n",
    "            if key not in freq.keys():\n",
    "                if target[i]==1:        #disasterous tweet\n",
    "                    freq[key]=[1,0]\n",
    "                else:                   #non-disasterous tweet\n",
    "                    freq[key]=[0,1]\n",
    "            else:\n",
    "                if target[i]==1:\n",
    "                    freq[key][0]+=1\n",
    "                else:\n",
    "                    freq[key][1]+=1\n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d572f97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=clean_tweet(data['text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52d74fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets=[]\n",
    "target=[]\n",
    "for i in range(len(data['text'])):\n",
    "    tweets.append(text[i])\n",
    "    target.append(data['target'].values[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65eafb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_dict=build_freq_dict(tweets,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5156effa",
   "metadata": {},
   "source": [
    "## Building features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e532d9",
   "metadata": {},
   "source": [
    "### Applying the tokenizer to convert each word to a unique number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "270b701f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e434923",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer()\n",
    "tokenizer.fit_on_texts(tweets)\n",
    "sequence=tokenizer.texts_to_sequences(tweets)\n",
    "#print(\"Before Tokenization: \\n\",tweets)\n",
    "#print(\"After Tokenization: \\n\",sequence)\n",
    "#len(sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92005074",
   "metadata": {},
   "source": [
    "### Making all inputs have the same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a741a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e8f51a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_sequence=pad_sequences(sequence,maxlen=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff83e15",
   "metadata": {},
   "source": [
    "## Splitting the data into train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0aceaf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X,test_X,train_y,test_y=train_test_split(np.array(padded_sequence),np.array(target),test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b6ec74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x shape:  (4064, 100)\n",
      "train_y shape:  (4064,)\n",
      "test_x shape:  (1016, 100)\n",
      "test_x shape:  (1016,)\n"
     ]
    }
   ],
   "source": [
    "print('train_x shape: ',train_X.shape)\n",
    "print('train_y shape: ',train_y.shape)\n",
    "print('test_x shape: ',test_X.shape)\n",
    "print('test_x shape: ',test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1259b0",
   "metadata": {},
   "source": [
    "### Reshaping the data for the LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4e06df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X=train_X.reshape(train_X.shape[0],1,train_X.shape[1])\n",
    "test_X=test_X.reshape(test_X.shape[0],1,test_X.shape[1])\n",
    "train_y=train_y.reshape(-1,1)\n",
    "test_y=test_y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "415b4401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x shape:  (4064, 1, 100)\n",
      "train_y shape:  (4064, 1)\n",
      "test_x shape:  (1016, 1, 100)\n",
      "test_x shape:  (1016, 1)\n"
     ]
    }
   ],
   "source": [
    "print('train_x shape: ',train_X.shape)\n",
    "print('train_y shape: ',train_y.shape)\n",
    "print('test_x shape: ',test_X.shape)\n",
    "print('test_x shape: ',test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15ab763",
   "metadata": {},
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "98e60c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Dense,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "13a851f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_20 (LSTM)              (None, 50)                30200     \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 50)                0         \n",
      "                                                                 \n",
      " dense_610 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_611 (Dense)           (None, 250)               12750     \n",
      "                                                                 \n",
      " dense_612 (Dense)           (None, 250)               62750     \n",
      "                                                                 \n",
      " dense_613 (Dense)           (None, 350)               87850     \n",
      "                                                                 \n",
      " dense_614 (Dense)           (None, 250)               87750     \n",
      "                                                                 \n",
      " dense_615 (Dense)           (None, 50)                12550     \n",
      "                                                                 \n",
      " dense_616 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_617 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_618 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_619 (Dense)           (None, 150)               7650      \n",
      "                                                                 \n",
      " dense_620 (Dense)           (None, 50)                7550      \n",
      "                                                                 \n",
      " dense_621 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_622 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_623 (Dense)           (None, 150)               7650      \n",
      "                                                                 \n",
      " dense_624 (Dense)           (None, 100)               15100     \n",
      "                                                                 \n",
      " dense_625 (Dense)           (None, 150)               15150     \n",
      "                                                                 \n",
      " dense_626 (Dense)           (None, 100)               15100     \n",
      "                                                                 \n",
      " dense_627 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_628 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_629 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_630 (Dense)           (None, 150)               7650      \n",
      "                                                                 \n",
      " dense_631 (Dense)           (None, 50)                7550      \n",
      "                                                                 \n",
      " dense_632 (Dense)           (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_633 (Dense)           (None, 100)               5100      \n",
      "                                                                 \n",
      " dense_634 (Dense)           (None, 150)               15150     \n",
      "                                                                 \n",
      " dense_635 (Dense)           (None, 100)               15100     \n",
      "                                                                 \n",
      " dense_636 (Dense)           (None, 150)               15150     \n",
      "                                                                 \n",
      " dense_637 (Dense)           (None, 100)               15100     \n",
      "                                                                 \n",
      " dense_638 (Dense)           (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_639 (Dense)           (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 481,051\n",
      "Trainable params: 481,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(LSTM(50,activation='relu',input_shape=(train_X.shape[1],train_X.shape[2])))  \n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(50,activation='relu'))\n",
    "model.add(Dense(250,activation='relu'))\n",
    "model.add(Dense(250,activation='relu'))\n",
    "model.add(Dense(350,activation='relu'))\n",
    "model.add(Dense(250,activation='relu'))\n",
    "model.add(Dense(50,activation='relu'))\n",
    "model.add(Dense(50,activation='relu'))\n",
    "model.add(Dense(50,activation='relu'))\n",
    "model.add(Dense(50,activation='relu'))\n",
    "model.add(Dense(150,activation='relu'))\n",
    "model.add(Dense(50,activation='relu'))\n",
    "model.add(Dense(50,activation='relu'))\n",
    "model.add(Dense(50,activation='relu'))\n",
    "\n",
    "\n",
    "model.add(Dense(150,activation='relu'))\n",
    "\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dense(150,activation='relu'))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dense(50,activation='relu'))\n",
    "model.add(Dense(50,activation='relu'))\n",
    "model.add(Dense(50,activation='relu'))\n",
    "model.add(Dense(150,activation='relu'))\n",
    "model.add(Dense(50,activation='relu'))\n",
    "model.add(Dense(50,activation='relu'))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dense(150,activation='relu'))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dense(150,activation='relu'))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "\n",
    "\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "67b2ed87",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "cb4b97aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "127/127 [==============================] - 2s 4ms/step - loss: 0.6882 - accuracy: 0.5620\n",
      "Epoch 2/70\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.6855 - accuracy: 0.5630\n",
      "Epoch 3/70\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6844 - accuracy: 0.5630\n",
      "Epoch 4/70\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.6826 - accuracy: 0.5701\n",
      "Epoch 5/70\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6834 - accuracy: 0.5699\n",
      "Epoch 6/70\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6850 - accuracy: 0.5655\n",
      "Epoch 7/70\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6841 - accuracy: 0.5672\n",
      "Epoch 8/70\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6830 - accuracy: 0.5687\n",
      "Epoch 9/70\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6842 - accuracy: 0.5578\n",
      "Epoch 10/70\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6849 - accuracy: 0.5630\n",
      "Epoch 11/70\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6853 - accuracy: 0.5637\n",
      "Epoch 12/70\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.6859 - accuracy: 0.5576\n",
      "Epoch 13/70\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.6859 - accuracy: 0.5630\n",
      "Epoch 14/70\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.6846 - accuracy: 0.5632\n",
      "Epoch 15/70\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6844 - accuracy: 0.5630\n",
      "Epoch 16/70\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6828 - accuracy: 0.5578\n",
      "Epoch 17/70\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.6832 - accuracy: 0.5630\n",
      "Epoch 18/70\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.6858 - accuracy: 0.5630\n",
      "Epoch 19/70\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6855 - accuracy: 0.5630\n",
      "Epoch 20/70\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6853 - accuracy: 0.5630\n",
      "Epoch 21/70\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6854 - accuracy: 0.5630\n",
      "Epoch 22/70\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.6852 - accuracy: 0.5630\n",
      "Epoch 23/70\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.6855 - accuracy: 0.5630\n",
      "Epoch 24/70\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6853 - accuracy: 0.5630\n",
      "Epoch 25/70\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.6854 - accuracy: 0.5630\n",
      "Epoch 26/70\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.6854 - accuracy: 0.5630\n",
      "Epoch 27/70\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.6854 - accuracy: 0.5630\n",
      "Epoch 28/70\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.6849 - accuracy: 0.5630\n",
      "Epoch 29/70\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.6842 - accuracy: 0.5586\n",
      "Epoch 30/70\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.6841 - accuracy: 0.5635\n",
      "Epoch 31/70\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.6818 - accuracy: 0.5635\n",
      "Epoch 32/70\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.6826 - accuracy: 0.5571\n",
      "Epoch 33/70\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.6792 - accuracy: 0.5704\n",
      "Epoch 34/70\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.6811 - accuracy: 0.5613\n",
      "Epoch 35/70\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.6775 - accuracy: 0.5630\n",
      "Epoch 36/70\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.6752 - accuracy: 0.5780\n",
      "Epoch 37/70\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6766 - accuracy: 0.5721\n",
      "Epoch 38/70\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6770 - accuracy: 0.5800\n",
      "Epoch 39/70\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.6729 - accuracy: 0.5928\n",
      "Epoch 40/70\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.6766 - accuracy: 0.5743\n",
      "Epoch 41/70\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.6713 - accuracy: 0.5913\n",
      "Epoch 42/70\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6702 - accuracy: 0.5869\n",
      "Epoch 43/70\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.6697 - accuracy: 0.5942\n",
      "Epoch 44/70\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.6676 - accuracy: 0.6014\n",
      "Epoch 45/70\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.6601 - accuracy: 0.6137\n",
      "Epoch 46/70\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6695 - accuracy: 0.5987\n",
      "Epoch 47/70\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6676 - accuracy: 0.5994\n",
      "Epoch 48/70\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.6632 - accuracy: 0.6063\n",
      "Epoch 49/70\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6628 - accuracy: 0.6056\n",
      "Epoch 50/70\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.6655 - accuracy: 0.6105\n",
      "Epoch 51/70\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6628 - accuracy: 0.6149\n",
      "Epoch 52/70\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.6604 - accuracy: 0.6193\n",
      "Epoch 53/70\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.6613 - accuracy: 0.6122\n",
      "Epoch 54/70\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6600 - accuracy: 0.6184\n",
      "Epoch 55/70\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.6606 - accuracy: 0.6129\n",
      "Epoch 56/70\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6555 - accuracy: 0.6267\n",
      "Epoch 57/70\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.6570 - accuracy: 0.6188\n",
      "Epoch 58/70\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6583 - accuracy: 0.6144\n",
      "Epoch 59/70\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.6607 - accuracy: 0.6073\n",
      "Epoch 60/70\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6571 - accuracy: 0.6105\n",
      "Epoch 61/70\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.6588 - accuracy: 0.6001\n",
      "Epoch 62/70\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.6570 - accuracy: 0.6097\n",
      "Epoch 63/70\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.6607 - accuracy: 0.5982\n",
      "Epoch 64/70\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.6624 - accuracy: 0.5888\n",
      "Epoch 65/70\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.6584 - accuracy: 0.6152\n",
      "Epoch 66/70\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.6570 - accuracy: 0.6159\n",
      "Epoch 67/70\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6548 - accuracy: 0.6181\n",
      "Epoch 68/70\n",
      "127/127 [==============================] - 0s 4ms/step - loss: 0.6559 - accuracy: 0.6198\n",
      "Epoch 69/70\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6525 - accuracy: 0.6230\n",
      "Epoch 70/70\n",
      "127/127 [==============================] - 0s 3ms/step - loss: 0.6533 - accuracy: 0.6213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22b3ae5cf40>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X,train_y,epochs=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "0b572d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df307704",
   "metadata": {},
   "source": [
    "\n",
    "#### test_y and y_pred are not of same type\n",
    "#### test_y : binary\n",
    "#### y_pred: continous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "ba1f0896",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict=[]\n",
    "for i in y_pred:\n",
    "    if i>=0.5:\n",
    "        y_predict.append(1)\n",
    "    else:\n",
    "        y_predict.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "1df4b38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy is:  60.03937007874016 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy=accuracy_score(test_y,y_predict)\n",
    "print('Model accuracy is: ',accuracy*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8040673a",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "731d5962",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "d0864923",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model=load_model('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349ad30f",
   "metadata": {},
   "source": [
    "### Testing the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "7350408a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Storm in RI worse than last hurricane. My city...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Green Line derailment in Chicago http://t.co/U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MEG issues Hazardous Weather Outlook (HWO) htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#CityofCalgary has activated its Municipal Eme...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         0     NaN      NaN   \n",
       "1         2     NaN      NaN   \n",
       "2         3     NaN      NaN   \n",
       "3         9     NaN      NaN   \n",
       "4        11     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "3258  10861     NaN      NaN   \n",
       "3259  10865     NaN      NaN   \n",
       "3260  10868     NaN      NaN   \n",
       "3261  10874     NaN      NaN   \n",
       "3262  10875     NaN      NaN   \n",
       "\n",
       "                                                   text  \n",
       "0                    Just happened a terrible car crash  \n",
       "1     Heard about #earthquake is different cities, s...  \n",
       "2     there is a forest fire at spot pond, geese are...  \n",
       "3              Apocalypse lighting. #Spokane #wildfires  \n",
       "4         Typhoon Soudelor kills 28 in China and Taiwan  \n",
       "...                                                 ...  \n",
       "3258  EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...  \n",
       "3259  Storm in RI worse than last hurricane. My city...  \n",
       "3260  Green Line derailment in Chicago http://t.co/U...  \n",
       "3261  MEG issues Hazardous Weather Outlook (HWO) htt...  \n",
       "3262  #CityofCalgary has activated its Municipal Eme...  \n",
       "\n",
       "[3263 rows x 4 columns]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv('test.csv')\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "2c72819b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>46</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>London</td>\n",
       "      <td>Birmingham Wholesale Market is ablaze BBC News...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>47</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Niall's place | SAF 12 SQUAD |</td>\n",
       "      <td>@sunkxssedharry will you wear shorts for race ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>51</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>NIGERIA</td>\n",
       "      <td>#PreviouslyOnDoyinTv: Toke MakinwaÛªs marriag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>58</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Live On Webcam</td>\n",
       "      <td>Check these out: http://t.co/rOI2NSmEJJ http:/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>60</td>\n",
       "      <td>ablaze</td>\n",
       "      <td>Los Angeles, Califnordia</td>\n",
       "      <td>PSA: IÛªm splitting my personalities.\\n\\n?? t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>10804</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>Love Reiss</td>\n",
       "      <td>@yakubOObs think he deactivated because his no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>10806</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>Seattle Washington</td>\n",
       "      <td>RT CNBC '3 words from Disney CEO Bob Iger wrec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3248</th>\n",
       "      <td>10807</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>Acey mountain islanddåÇTorontoåÈ</td>\n",
       "      <td>Smackdown tyme this should put me in a good mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3249</th>\n",
       "      <td>10816</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>los angeles</td>\n",
       "      <td>@thrillhho jsyk I haven't stopped thinking abt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3250</th>\n",
       "      <td>10820</td>\n",
       "      <td>wrecked</td>\n",
       "      <td>Brussels, Belgium</td>\n",
       "      <td>@stighefootball Begovic has been garbage. He g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2158 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  keyword                          location  \\\n",
       "15       46   ablaze                            London   \n",
       "16       47   ablaze    Niall's place | SAF 12 SQUAD |   \n",
       "17       51   ablaze                           NIGERIA   \n",
       "18       58   ablaze                    Live On Webcam   \n",
       "19       60   ablaze          Los Angeles, Califnordia   \n",
       "...     ...      ...                               ...   \n",
       "3246  10804  wrecked                        Love Reiss   \n",
       "3247  10806  wrecked                Seattle Washington   \n",
       "3248  10807  wrecked  Acey mountain islanddåÇTorontoåÈ   \n",
       "3249  10816  wrecked                       los angeles   \n",
       "3250  10820  wrecked                 Brussels, Belgium   \n",
       "\n",
       "                                                   text  \n",
       "15    Birmingham Wholesale Market is ablaze BBC News...  \n",
       "16    @sunkxssedharry will you wear shorts for race ...  \n",
       "17    #PreviouslyOnDoyinTv: Toke MakinwaÛªs marriag...  \n",
       "18    Check these out: http://t.co/rOI2NSmEJJ http:/...  \n",
       "19    PSA: IÛªm splitting my personalities.\\n\\n?? t...  \n",
       "...                                                 ...  \n",
       "3246  @yakubOObs think he deactivated because his no...  \n",
       "3247  RT CNBC '3 words from Disney CEO Bob Iger wrec...  \n",
       "3248  Smackdown tyme this should put me in a good mo...  \n",
       "3249  @thrillhho jsyk I haven't stopped thinking abt...  \n",
       "3250  @stighefootball Begovic has been garbage. He g...  \n",
       "\n",
       "[2158 rows x 4 columns]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=test_data.dropna()\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "96d8e930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded Sequence:  [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0 452]]\n"
     ]
    }
   ],
   "source": [
    "test=['What a nice hat?']\n",
    "x=tokenizer.texts_to_sequences(clean_tweet(test))\n",
    "padded_sequence=pad_sequences(x,maxlen=100)\n",
    "print('Padded Sequence: ',padded_sequence)\n",
    "padded_sequence=padded_sequence.reshape(padded_sequence.shape[0],1,padded_sequence.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "21302cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 13ms/step\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "result=np.argmax(model.predict(np.array(padded_sequence)))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa9996d",
   "metadata": {},
   "source": [
    "###### Non-disasterous tweet detected"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
